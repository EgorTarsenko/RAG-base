{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aeaee4a-58b8-45cc-8b60-8c57689613a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set `PYTHONPATH` to include the project's home directory. \n",
    "PROJECT_HOME = Path(os.environ.get('PROJECT_HOME', Path.cwd() / '..')).resolve()\n",
    "sys.path.append(str(PROJECT_HOME))\n",
    "\n",
    "from app.databases.vector import VectorDB\n",
    "from app.indexing.text.context_aware import ContextAwareIndexing\n",
    "from app.indexing.metadata import DocumentMetadata\n",
    "from app.models.inference.openai_model import ChatOpenAI\n",
    "from app.server.llm import LLMAgent, LLMEventType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f0e0e1-f220-44ba-aff8-1d472c5ed8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and set environment\n",
    "dotenv.load_dotenv()\n",
    "os.environ['USER_AGENT'] = 'myagent'\n",
    "os.environ['LLM_MODEL_ID'] = 'anthropic.claude-3-5-sonnet-20240620-v1:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ca0d7-676c-4144-905a-1a1ff51a824c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# The problem\n",
    "\n",
    "Here we're initializing a vector DB with the NYC CPC (City Planning Commision) Reports. The reports can be found [here](https://a030-cpc.nyc.gov/html/cpc/index.aspx). Since there are a lot of reports, going all the way back to 1938, we've decided to use reports only from Midtown, Manhattan, from 2010 up to November 2024.\n",
    "\n",
    "You can download the reports yourself, or use (this link)[TODO] to download a zip file with the reports that we've used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23290c3-f756-47e3-ac2a-4df9f5d4a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the vector DB collection to use and the directory with the files to load\n",
    "os.environ['DEFAULT_VECTOR_DB_COLLECTION_NAME'] = 'cch_nyc_city_planning'\n",
    "docs_path = PROJECT_HOME / 'data' / 'nyc-planning'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ae1d8-d662-4731-915b-db016693478d",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We'll start by loading all the PDFs without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe96475-e8ce-402e-bc72-99059c22c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a function, because we're going to reuse it in the next section.\n",
    "\n",
    "async def load_all_pdfs(path_to_load: Path, vector_db: VectorDB) -> None:\n",
    "    \"\"\"Load all PDFs in `path_to_load` into `vector_db`\"\"\"\n",
    "    \n",
    "    # Go over all the files in the data directory\n",
    "    for pdf_path in tqdm(list(path_to_load.glob('*.pdf'))):\n",
    "    \n",
    "        # Load the file.\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        docs = [p for p in loader.lazy_load()]\n",
    "    \n",
    "        # Store the file in the vector DB.\n",
    "        await vector_db.split_and_store_text(docs, metadata=DocumentMetadata(\n",
    "    \n",
    "            # In our case, the filename is unique, but you may want to choose a different ID and Name, in other cases.\n",
    "            source_id=pdf_path.stem,\n",
    "            source_name=pdf_path.name,\n",
    "            \n",
    "            # Note that `modified_at` is the time that it was modified accodrding to your local file system.\n",
    "            # IRL you may want to use the date of the report. We won't go into it here.\n",
    "            modified_at=datetime.fromtimestamp(os.path.getmtime(pdf_path)),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc87424-a2c8-48fa-a1f2-8e8a94ff7ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Chroma database at chromadb:8000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e8174beb38448e8c8134721e7e921a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop the existing collection, if necessary.\n",
    "vector_db = VectorDB(drop_old=True)\n",
    "await load_all_pdfs(docs_path, vector_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35abeb9d-6e60-4679-9f92-b930722a6a42",
   "metadata": {},
   "source": [
    "## Chatting with our Bot\n",
    "----\n",
    "\n",
    "To see the problem, you'll need to ask about something that's buried in the documents, but doesn't have a context near by.\n",
    "\n",
    "For example, you can try asking: \n",
    "> Can you give a list of environmental reviews and the associated projects?\n",
    "\n",
    "The `Environmental Reviews` are usually in the middle of the document and usually don't contain information about the project name or address. At most, the model can infere the project ID from the name of the file which exists in the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e64c25d-1132-4fae-9661-547f2ef867a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_rag_bot(user_config: dict, print_debug_info: bool = False) -> None:\n",
    "    \"\"\"Facilitates a conversation with our RAG ChatBot.\n",
    "\n",
    "    :param `user_config`: Mainly used to store the conversation ID and keep history of previous conversations.\n",
    "    :param `print_debug_info`: If `True`, will print debuge messages, such as the retrieval quetion and results. Defaults to `False`.\n",
    "    \"\"\"\n",
    "    async with LLMAgent() as llm_agent:\n",
    "        while True:\n",
    "            # Make a pretty separator for the next human message\n",
    "            HumanMessage('').pretty_print()\n",
    "            \n",
    "            # Get user question.\n",
    "            message = input('Write a question to the LLM. Write `q` or `quit` to exit:')\n",
    "            \n",
    "            # System output\n",
    "            SystemMessage('').pretty_print()\n",
    "    \n",
    "            # Check if user wants to quit\n",
    "            if message.lower() in ('q', 'quit'):\n",
    "                print('Quitting for now. You can continue the conversation by rerunning this cell')\n",
    "                break\n",
    "    \n",
    "            # Get ChatBot's response.\n",
    "            async for chat_msg in llm_agent.astream_events(message, user_config):\n",
    "                if chat_msg.type == LLMEventType.CHAT_CHUNK:\n",
    "                    print(chat_msg.content, end='')\n",
    "                elif print_debug_info:\n",
    "                    print(chat_msg.to_dict())\n",
    "    \n",
    "            # New line.\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e65d17d-6650-4143-b601-0cb6ab514162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Chroma database at chromadb:8000\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Write a question to the LLM. Write `q` or `quit` to exit: Can you give a list of environmental reviews and the associated projects?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! To answer your question about environmental reviews and their associated projects, I'll need to search our company's internal information. Let me use the Internal Company Info Retriever to find this information for you.\n",
      "\n",
      "Based on the information retrieved, I can provide you with a list of environmental reviews and their associated projects. Here are the sources I'll be using:\n",
      "\n",
      "[1] - 100049 | 100049.pdf | 2024-11-13T10:02:19.399237 | (0: This application (C 100049 ZSM), in conjunction with the applications for the related actions (C 100047 ZMM, N 100048 ZRM, C 100050 ZSM, and C 100237 PQM) was reviewed pursuant to the New York State Environmental Quality Review Act (SEQRA), and the SEQRA regulations)\n",
      "\n",
      "[2] - 210415 | 210415.pdf | 2024-11-13T09:57:08.701722 | (0: The application (C 210415 ZSM), in conjunction with the applications for the related actions (C 210412 ZSM, C 210413 ZSM, C 210414 ZSM, N 210416 ZRM, and C 210417 PPM) was reviewed pursuant to the New York State Environmental Quality Review Act (SEQRA), and the SEQRA regulations)\n",
      "\n",
      "[3] - 130247a | 130247a.pdf | 2024-11-13T10:01:14.090973 | (0: This application (N 130247(A) ZRM), in conjunction with the applications for the related actions (C 130248 ZMM and N 130247 ZRM) was reviewed pursuant to the New York State Environmental Quality Review Act (SEQRA), and the SEQRA regulations)\n",
      "\n",
      "[4] - 150128 | 150128.pdf | 2024-11-13T10:00:27.051189 | (0: The application (C 150128 ZSM), along with the related applications (C 140440 MMM, N 150127 ZRM, C 150129 ZSM, C 150130 ZSM and C 150130(A) ZSM), was reviewed pursuant to the New York State Environmental Quality Review Act (SEQRA), and the SEQRA regulations)\n",
      "\n",
      "[5] - 150127 | 150127.pdf | 2024-11-13T10:00:31.259686 | (0: It was determined that the proposed actions may have a significant effect on the environment. A Positive Declaration was issued on June 16, 2014, and distributed, published and filed. Together with the Positive Declaration, a Draft Scope of Work for the Draft Environmental Impact Statement (DEIS) was issued on June 16, 2014.)\n",
      "\n",
      "+++++++++++++\n",
      "\n",
      "Based on the information provided, here is a list of environmental reviews and their associated projects:\n",
      "\n",
      "1. CEQR Number: 03DCP031M\n",
      "   Project: C 100049 ZSM and related actions (C 100047 ZMM, N 100048 ZRM, C 100050 ZSM, and C 100237 PQM)\n",
      "   Review Type: Environmental Impact Statement (EIS)\n",
      "\n",
      "2. CEQR Number: 21DCP057M\n",
      "   Project: C 210415 ZSM and related actions (C 210412 ZSM, C 210413 ZSM, C 210414 ZSM, N 210416 ZRM, and C 210417 PPM)\n",
      "   Review Type: Not specified in the given information\n",
      "\n",
      "3. CEQR Number: 13DCP011M\n",
      "   Project: N 130247(A) ZRM and related actions (C 130248 ZMM and N 130247 ZRM)\n",
      "   Review Type: Environmental Impact Statement (EIS)\n",
      "\n",
      "4. CEQR Number: 14DCP188M\n",
      "   Project: C 150128 ZSM and related actions (C 140440 MMM, N 150127 ZRM, C 150129 ZSM, C 150130 ZSM and C 150130(A) ZSM)\n",
      "   Review Type: Environmental Impact Statement (EIS)\n",
      "\n",
      "These environmental reviews were conducted pursuant to the New York State Environmental Quality Review Act (SEQRA) and the New York City Environmental Quality Review (CEQR) procedures. The reviews typically involved the preparation of Environmental Impact Statements (EIS) for projects that were determined to potentially have significant effects on\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Write a question to the LLM. Write `q` or `quit` to exit: q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "Quitting for now. You can continue the conversation by rerunning this cell\n"
     ]
    }
   ],
   "source": [
    "# To start a new conversation (delete history), change the `thread_id` to a new value and rerun the cell.\n",
    "user_config = {\"configurable\": {\"thread_id\": \"user_20_000\"}}\n",
    "\n",
    "await chat_with_rag_bot(user_config, print_debug_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3ef5db-0b5c-4371-b254-32ce6cec8ca0",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Adding Contextual Chunk Headers\n",
    "\n",
    "To solve the problem, we'll use Contextual Chunk Headers. That is, we'll add context to each chunk stored in the vector DB, so that the LLM will better know what it's related to.\n",
    "\n",
    "In our case, we'll ask an LLM to first summarize the document into a few sentences, then we'll store this summary along each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9082a0-06ba-4060-9980-61773ae7fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a different collection for the data with the context.\n",
    "# This will make it easier to go back and forth between the different collections.\n",
    "os.environ['DEFAULT_VECTOR_DB_COLLECTION_NAME'] = 'cch_nyc_city_planning_with_context'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08cc8c82-57c5-4eaa-addf-5bee84108abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Chroma database at chromadb:8000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df17521cd01c4b4784f0a005a26f514b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2 things to note:\n",
    "# 1. Use the `ContextAwareIndexing` strategy. You can look at the code that implements it to see all the details of how it works\n",
    "# 2. We use `gpt-3.5-turbo` to summarize the texts. You can of course choose to use a different model, depending on your use-case. For us, we try to use a fast model that's good enough(TM).\n",
    "vector_db = VectorDB(\n",
    "    drop_old=True,\n",
    "    split_strategy=ContextAwareIndexing(chat_model=ChatOpenAI(model_id='gpt-3.5-turbo')),\n",
    ")\n",
    "\n",
    "# Use the same function to load the data, the difference is in the strategy used by `vector_db`.\n",
    "await load_all_pdfs(docs_path, vector_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f15f96-2097-4ebd-a921-67aa7a09d9c1",
   "metadata": {},
   "source": [
    "## Chatting with our Bot\n",
    "----\n",
    "\n",
    "Same as before, but now with additional context, the LLM should be able to answer your previous question based on the additional context it recieves.\n",
    "\n",
    "Try asking again:\n",
    "> Can you give a list of environmental reviews and the associated projects?\n",
    "\n",
    "How is the answer different from the previous time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dff6e58-6239-4e99-852f-03d8c4905ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Chroma database at chromadb:8000\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Write a question to the LLM. Write `q` or `quit` to exit: Can you give a list of environmental reviews and the associated projects?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "Certainly! Based on the information retrieved, I can provide you with a list of environmental reviews and their associated projects. Here's the list:\n",
      "\n",
      "1. CEQR Number: 14DCP188M\n",
      "   Project: Commercial building development in Manhattan (Green 317 Madison LLC and Green 110 East 42nd LLC)\n",
      "   Associated Applications: C 150128 ZSM, C 140440 MMM, N 150127 ZRM, C 150129 ZSM, C 150130 ZSM, and C 150130(A) ZSM\n",
      "   Lead Agency: City Planning Commission\n",
      "\n",
      "2. CEQR Number: 21DCP057M\n",
      "   Project: 175 Park Avenue (Commodore Owner, LLC)\n",
      "   Associated Applications: C 210415 ZSM, C 210412 ZSM, C 210413 ZSM, C 210414 ZSM, N 210416 ZRM, and C 210417 PPM\n",
      "   Lead Agency: City Planning Commission\n",
      "\n",
      "3. CEQR Number: 13DCP011M\n",
      "   Project: East Midtown Rezoning\n",
      "   Associated Applications: N 130247(A) ZRM, C 130248 ZMM, and N 130247 ZRM\n",
      "   Lead Agency: City Planning Commission\n",
      "\n",
      "4. CEQR Number: 16DCP136M\n",
      "   Project: Theater Subdistrict Fund Text Amendment\n",
      "   Associated Application: N 160254 ZRM (inferred from the context)\n",
      "   Lead Agency: City Planning Commission\n",
      "\n",
      "These environmental reviews were conducted pursuant to the New York State Environmental Quality Review Act (SEQRA) and the New York City Environmental Quality Review (CEQR) Rules of Procedure. Each review is associated with specific development projects or zoning amendments in Manhattan, particularly in the Midtown and East Midtown areas.\n",
      "\n",
      "The reviews cover various aspects of environmental impact, including but not limited to hazardous materials, air quality, noise, traffic, and pedestrian impacts. In some cases, the reviews resulted in the placement of (E) designations on development sites to avoid significant adverse impacts.\n",
      "\n",
      "It's important to note that these environmental reviews are part of the larger land use review process for each project, which often includes multiple related actions and applications.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Write a question to the LLM. Write `q` or `quit` to exit: q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "Quitting for now. You can continue the conversation by rerunning this cell\n"
     ]
    }
   ],
   "source": [
    "# To start a new conversation (delete history), change the `thread_id` to a new value and rerun the cell.\n",
    "# Note that we use a new `thread_id` from the previous one, to start \"fresh\".\n",
    "user_config = {\"configurable\": {\"thread_id\": \"user_30_000\"}}\n",
    "\n",
    "await chat_with_rag_bot(user_config, print_debug_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ad0dc-8f3c-4d5a-a218-509374a76b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
